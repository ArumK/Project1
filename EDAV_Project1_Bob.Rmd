---
title: "EDAV_Project1"
author: "Team"
date: "January 28, 2016"
output: html_document
---

Load the data:
```{r, warnings = FALSE, message=FALSE}
#Set your working directory
setwd('/Users/bobminnich/Documents/Columbia/Courses/DataVisualization/EDAV_Project1')
library(dplyr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(ggplot2)


#Load CSV file into Data Frame
df = read.csv("Survey+Response.csv")

col.list = c("Matlab", "R", "Github", "Excel", "SQL", "RStudio", "ggplot2", "shell (terminal / command line)", "C/C++", "Python", "Stata", "LaTeX", "XML", "Web: html css js", "google drive (formerly docs)", "Sweave/knitr","dropbox", "SPSS", "regular expressions (grep)", "lattice" )

#Count Columns with NAs
na.check = df%>%is.na() %>% apply(2,sum)

#Remove NAs
df_clean = df[,which(na.check==0)]

#Create colums initializing at 0
df_clean[,col.list] = 0

for(i in col.list){
  #Need an If Statement because of R vs RStudio. 
    if(i == "R"){ 
      #Use Reg expressions "R,|R$" which looks for "R," and for "R$" which means there is nothing after R (line 87 caused this issue)
      fnd = "R,|R$"
      #try to find fnd within the vector, return Row # if True
      rows = grep(pattern = fnd, x = df_clean$Experiences.with.tools)
    }else{
      #Same as above
      fnd = paste(i, sep = "")
      rows = grep(pattern = fnd, x = df_clean$Experiences.with.tools, fixed = TRUE)
      }
    df_clean[rows,i] = 1
}
```

Decision Tree
We will now look at a decision tree to try and understand if we have the ability to predict what program a student is in only the student's experience with the software programs and tools listed in the survey.

We have chosen a decision tree because the intrepetability is high and can give us some insight into what categories help create the purest subgroups using the Gini Index

Right now we will split the training set to 80% of the given data and attempt to predict on the remaining 20% to get an idea of how this prediction algorithm might perform.
```{r}
#Renaming the columnbs because of issues with speicific characterswithin the column names.
col.list2 = c("Matlab", "R", "Github", "Excel", "SQL", "RStudio", "ggplot2", "shell", "C", "Python", "Stata", "LaTeX", "XML", "Web", "google_drive", "knitr","dropbox", "SPSS", "reg_ex", "lattice" )

colnames(df_clean) = c(colnames(df_clean)[1:11], col.list2)

#Set random seed so that we do introduce any bias
set.seed(1)
train_in = sample(c(1:nrow(df_clean)), floor(0.8*nrow(df_clean)))

#Training Set
train = df_clean[train_in,]

#Test Set
test = df_clean[-train_in,]

```

```{r}
#Fit the model using all variables 
fit <- rpart(Program ~ Matlab+R+Github+Excel+SQL+RStudio+ggplot2+shell+C+Python+Stata+LaTeX+XML+Web+google_drive+knitr+dropbox+SPSS+reg_ex+lattice, data=train, method = "class")

#Create prediction
pred <- predict(fit, newdata=test, type = "class")

rpart.plot(fit, cex = 0.8)
plot(fit,uniform=FALSE,margin=0.2, nspace = 2, branch = 0.5, compress = TRUE)
text(fit, cex = 0.8,,srt=85,col=rainbow(5)[1:25],srt=20)

prp(fit, min.auto.cex	= 0.05, varlen = 100 ,nn.box.col = rainbow(10)[1:25])
```
We can see from the training data the tree has selected "Python" as the most 
```{r}
predictions =   predict(fit, test,type = "class")
percent_correct = sum(predictions==test$Program)/length(test$Program)
print(paste("The percent correct for the Decision Tree is ", percent_correct))
```


```{r}
train$Program = factor(train$Program)
#test$Program = factor(test$Program, levels=levels(train$Program))
test$Program = factor(test$Program)
formulatest = formula("Program ~ Matlab+R+Github+Excel+SQL+RStudio+ggplot2+shell+C+Python+Stata+LaTeX+XML+Web+google_drive+knitr+dropbox+SPSS+reg_ex+lattice")
rf = randomForest(formulatest,data=train,ntree=40)

output_rf = importance(rf)
x = (row.names(output_rf))
y = as.numeric(output_rf)
pdf = data.frame(cbind(x,y))
pdf$y = as.numeric(pdf$y)
pdf$x <- factor(pdf$x, levels = pdf$x[order(pdf$y)])

ggplot(data = pdf,aes(x=x, y = y)) + 
  geom_bar(stat='identity',aes(x, fill=y)) + 
  coord_flip() + 
  ggtitle("Random Forest - Importance")


output = predict(rf, test, type = "response", na.action(na.omit))
percent_correct = sum(as.character(output) == as.character(test$Program))/nrow(test)

print(paste("The percent correct for the Random Forest is ", percent_correct))

y = c()
for(i in seq(1,500,5)){
  rf = randomForest(formulatest,data=train,ntree=i)
  output = predict(rf, test, type = "response", na.action(na.omit))
  percent_correct = sum(as.character(output) == as.character(test$Program))/nrow(test)
  y = c(y,percent_correct)
}

pl_df = data.frame(y)
ggplot(data=pl_df, aes(x=seq(1,500,5), y=y)) +
    geom_line() +
    geom_point() +
    xlab("Number of Random Forest Trees") + ylab("%Correct") +
    ggtitle("Number of Trees vs Classification Percent Correct")

```

```{r}
y = c()
for(i in seq(2,nrow(train),2)){
  index = as.numeric(row.names(train))[1:i]
  newtrain = train[c(1:i),]
  newtrain$Program = factor(newtrain$Program)
  test$Program = factor(test$Program, levels=levels(df_clean$Program))
  #test$Program = factor(test$Program)

  rf = randomForest(formulatest,data=newtrain,ntree=40)
  output = predict(rf, test, type = "response", na.action(na.omit))
  
  percent_correct = sum(as.character(output) == as.character(test$Program))/nrow(test)
  y = c(y,percent_correct)
}
pl_df = data.frame(seq(2,nrow(train),2),y)
colnames(pl_df) = c("x","y")
ggplot(data=pl_df, aes(x=x, y=y)) +
    geom_point() + stat_smooth(se = TRUE) + 
    xlab("Training Samples") + ylab("%Correct") +
    ggtitle("Training Curves")

```
  
